
Conditional probability that feature f = fv given that g = gv
  multiplied by the log count of cooccurrence
  multiplied by the mutual information of features f and g
Only the strongest signal (source feature) is taken, all other source features are ignored.

( perl scripts/train_and_predict_dz.pl --score plogcinf --model strongest --debug > outputs/cond_prob_info.csv ) |& tee outputs/cond_prob_info.debug
Correctly predicted 1134 features out of 1596 total predictions, accuracy = 71.05%
python3 scripts/evaluate_from_csv.py --input_file data/dev_x.csv --output_file outputs/cond_prob_info.csv --golden_file data/dev_y.csv
Accuracy is 69.99%

There is some disagreement in the evaluation. As I look at the gold standard
immediately after each prediction in order to analyze errors, I also compute
accuracy internally and gives higher numbers than our external evaluation
script.

Also, I am struggling to make the prediction deterministic. So far it still oscilates between several possible outcomes:
correct 1136 out of 1596, accuracy 71.18% (external evaluation 70.11%)
correct 1135 out of 1596, accuracy 71.12% (external evaluation 70.05%)
correct 1134 out of 1596, accuracy 71.05% (external evaluation 69.99%)
correct 1132 out of 1596, accuracy 70.93% (external evaluation 69.86%)

