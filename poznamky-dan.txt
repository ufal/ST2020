Repozitář github.com/ufal/ST2020 (založil Ruda).

TO DO:

Vylepšit analýzu chyb. Pokud nějaký rys předpovím špatně, byla vůbec šance předpovědět ho dobře, tj., stalo se
v trénovacích datech alespoň jednou, že něco, co teď mám na vstupu, se vyskytlo spolu se správnou odpovědí?
Soustředit se na případy, kde nějakou šanci máme. A spočítat, jaké procento případů je takových, že máme šanci;
tohle bude horní mez úspěšnosti, které můžeme dosáhnout.

Countrycodes by možná byly užitečnější, kdybych rozsekal případy, kdy jeden jazyk má několik zemí, na binární
rysy (countryCZ = yes).

Clustering jazyků podle vzdálenosti od jednoho z předem připravených bodů (např. Evropa, Kavkaz).
Nebo k-means, ale místo náhodného rozmístění počátečních centroidů asi zase zvolit body ručně.

Zakomponovat druh rysu, aby lexikální rys jako Hand_and_Arm nezávisel třeba na morfologii.

Měli bychom otestovat, zda se na pořadí metod něco změní, když dostaneme na vstupu výrazně více nebo výrazně
méně vyplněných rysů. (Organizátoři řekli, že těch rysů dostaneme "a handful". Nic přesnějšího nevíme.)

Ještě se znova podívat na to, proč nefunguje hlasování více rysů.

Pozor, někdy se rozhodnu pro zdrojový rys, ale jeho 1. i 2. odpověď se téměř neliší ve skóre! To bych se pak měl zeptat třetího.

Self training: vybrat takový otazník, kde si jsme nejvíce jisti predikcí, pak ho vzít jako součást
znalosti a zkusit, jestli nedokážu předpovědět něco dalšího?

10.6.:

Pouze 13 hodnot (z 1596 v dev datech) nemáme z čeho předpovědět. Teoreticky tedy můžeme dosáhnout úspěšnosti 99 %.
Ale: dalších 81 hodnot taky nemůžeme předpovědět, protože ve všech případech je pravděpodobnější něco jiného. To by byl strop 94 %.

Asi by pomohlo jemnější rozčlenění Země, u chybných předpovědí často vidím latlon jako viníka (i když jinde zase pomohl).

Co určitě zkusit: Martin (pokus s názvem lang_embedding) předpovídá X, pro mě je to další vstupní údaj.
Zjistit, jak moc se lišíme (Ruda tuším spočítal, že kdyby Orákulum vybíralo ze mne a z Martina, přelezli bychom 80 %).
Pozor, v Martinově výstupu jsou momentálně posunuté úvodní sloupce.
Taky bych mohl využít své skóre. Když jsem si hodně jistej (skóre větší než práh), mám častěji pravdu?



Další neuspořádané poznámky

* Hamming distance mezi jazyky
* Kilometrová vzdálenost jazyků https://en.wikipedia.org/wiki/Geographical_distance
* Hal Daumé III (2009), Bayesovské sítě, prý mají někde ke stažení implementaci a přehled implikací mezi rysy, které objevili.
* Zvýšit váhu implikací z rodiny a rodu (pokud existují, třeba je přičíst ke všem ostatním predikcím?)

* RR 12.5.2020: regrese neuronkou. Dostane řádek z WALSu. Má říct, nakolik je to správně. Nefunguje to.
* MV 12.5.2020: maskovanej vstup jako v transformerech. Nic moc, ještě si s tím hraje.
* MV zatím nejlepší (73,8 %): lang id + feature value ... ptá se neuronky, zda je to dobře.
  language embedding, používá i dev data (bez těch chybějících hodnot)
  viz lang_embedding.readme
  Embeddingy jazyků lépe modelují podobnost jazyků než Hamming distance.
